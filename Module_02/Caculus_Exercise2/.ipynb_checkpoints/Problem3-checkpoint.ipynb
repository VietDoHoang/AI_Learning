{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1eb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1fe180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column(data, index):\n",
    "    result = [row[index] for row in data]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7fdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(data1, data2, data3):\n",
    "    max_data_1 = max(data1)\n",
    "    max_data_2 = max(data2)\n",
    "    max_data_3 = max(data3)\n",
    "\n",
    "    min_data_1 = min(data1)\n",
    "    min_data_2 = min(data2)\n",
    "    min_data_3 = min(data3)\n",
    "\n",
    "    \n",
    "    # Implement your code to normalize data1, data2, data3 using min and max value\n",
    "    data1 = [(x - min_data_1)/(max_data_1-min_data_1) for x in data1]\n",
    "    return (data1, data2, data3), (max_data_1, max_data_2, max_data_3, min_data_1, min_data_2, min_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f424eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_name_dataset):\n",
    "  data = np.genfromtxt(file_name_dataset, delimiter=',', skip_header=1).tolist()\n",
    "\n",
    "  # get tv (index=0)\n",
    "  tv_data = get_column(data, 0)\n",
    "\n",
    "  # get radio (index=1)\n",
    "  radio_data = get_column(data, 1)\n",
    "\n",
    "  # get newspaper (index=2)\n",
    "  newspaper_data = get_column(data, 2)\n",
    "\n",
    "  # get sales (index=3)\n",
    "  sales_data = get_column(data, 3)\n",
    "\n",
    "  # scale data (only for features)\n",
    "  # remenber to scale input features in inference, therefore, we need to save max, min and mean values\n",
    "  (tv_data, radio_data, newspaper_data), (max_data_1, max_data_2, max_data_3, min_data_1, min_data_2, min_data_3) = min_max_scaling(tv_data,radio_data,newspaper_data)\n",
    "\n",
    "  # building X input  and y output for training\n",
    "  #Create list of features for input\n",
    "  X = [[1, x1, x2, x3] for x1, x2, x3 in zip(tv_data, radio_data, newspaper_data)]\n",
    "  y = sales_data\n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf62e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_features, weights):\n",
    "    return sum([f*w for f, w in zip(X_features, weights)])\n",
    "\n",
    "def compute_loss(y_hat, y):\n",
    "    return (y_hat - y)**2\n",
    "\n",
    "# compute gradient\n",
    "def compute_gradient_w(X_features, y, y_hat):\n",
    "    dl_dweights = [2*xi*(y_hat-y) for xi in X_features] \n",
    "    return dl_dweights \n",
    "\n",
    "# update weights\n",
    "def update_weight(weights, dl_dweights, lr):\n",
    "    weights = [w - lr*dw for w, dw in zip(weights, dl_dweights)] \n",
    "    return weights    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a1699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params():\n",
    "    bias = 0\n",
    "    w1 = random.gauss(mu=0.0, sigma=0.01)\n",
    "    w2 = random.gauss(mu=0.0, sigma=0.01)\n",
    "    w3 = random.gauss(mu=0.0, sigma=0.01)\n",
    "    \n",
    "    return [0, 0.016992259082509283, 0.0070783670518262355, -0.002307860847821344]\n",
    "    # return [bias, w1, w2, w3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_linear_regression(X_feature, y_ouput, epoch_max=50, lr=0.01):\n",
    "\n",
    "  losses = []\n",
    "  weights = initialize_params()\n",
    "  N = len(y_ouput)\n",
    "  for epoch in range(epoch_max):\n",
    "      print(\"epoch\", epoch)\n",
    "      for i in range(N):\n",
    "          # get a sample - row i     \n",
    "          features_i = X_feature[i]\n",
    "          y = y_ouput[i]\n",
    "          \n",
    "          # compute output \n",
    "          y_hat = predict(features_i, weights)\n",
    "\n",
    "          # compute loss\n",
    "          loss = compute_loss(y, y_hat)\n",
    "\n",
    "          # compute gradient w1, w2, w3, b\n",
    "          dl_dweights = compute_gradient_w(features_i, y, y_hat)\n",
    "\n",
    "          # update parameters\n",
    "          weights = update_weight(weights, dl_dweights, lr)\n",
    "\n",
    "          # logging\n",
    "          losses.append(loss) \n",
    "  return weights, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920c0017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X,y \u001b[38;5;241m=\u001b[39m prepare_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madvertising.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m W,L \u001b[38;5;241m=\u001b[39m \u001b[43mimplement_linear_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(L[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m, in \u001b[0;36mimplement_linear_regression\u001b[1;34m(X_feature, y_ouput, epoch_max, lr)\u001b[0m\n\u001b[0;32m     14\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m predict(features_i, weights)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# compute gradient w1, w2, w3, b\u001b[39;00m\n\u001b[0;32m     20\u001b[0m dl_dweights \u001b[38;5;241m=\u001b[39m compute_gradient_w(features_i, y, y_hat)\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mcompute_loss\u001b[1;34m(y_hat, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(y_hat, y):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n",
      "\u001b[1;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "X,y = prepare_data('advertising.csv')\n",
    "W,L = implement_linear_regression(X,y)\n",
    "plt.plot(L[0:100])\n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac18abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
